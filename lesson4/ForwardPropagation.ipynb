{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using matrix multiplication allows us to pass multiple inputs through at once by simply adding rows to the matrix X. Weâ€™re going to use matrices to pass through multiple inputs at once. Doing this allows for big computational speedups. \n",
    "\n",
    "\n",
    "Our input data matrix, X, is of dimension 3 by 2, because we have 3, 2-dimensional examples. Our corresponding output data, y, is of dimension 3 by 1.\n",
    "\n",
    "W (3,3) X (3,2) --> y (3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        # hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hidderLayerSize = 3\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # propagate inputs though network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input value, or element in matrix X, needs to be multiplied by a corresponding weight and then added together with all the other results for each neuron.\n",
    "\n",
    "From here on out, we'll refer to these matrics as X, W one, and z two, where z two the activity of our second layer. Notice that each entry in z is a sum of weighted inputs to each hidden neuron. Z is of size 3 by 3, one row for each example, and one column for each hidden unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z^{(2)} = XW^{(1)}$. Matrix notation is really nice here, the underlying process in a single line!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z^{(2)} = XW^{(1)} \\tag{1}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x111801e50>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSOUuIpKCVO4iIino/wPz2a8WEmZ8hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1116ca5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testInput = np.arange(-6,6,0.01)\n",
    "plt.plot(testInput, sigmoid(testInput), linewidth= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now have our second formula for forward propagation, using f to denote our activation function, we can write that a two, our second layer activity, is equal to f of z two. a two will be a matrix of the same size as z two, 3 by 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a^{(2)} = f(z^{(2)}) \\tag{2}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish forward propagation we need to propagate a two all the way to the output, yhat. Multiplying a2, by W2, z3 has three activity values, one for each example. We'll apply our activation function to z three yielding our official estimate of your test score, yHat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z^{(3)} = a^{(2)}W^{(2)} \\tag{3}\\\\\n",
    "$$\n",
    "$$\n",
    "\\hat{y} = f(z^{(3)}) \\tag{4}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We need to implement our forward propagation formulas in python. First we'll initialize our weight matrices in our init method. For starting values, we'll use random numbers. \n",
    "We'll implement forward propagation in our forward method, using numpy's built in dot method for matrix multiplication and our own sigmoid method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propagate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Forward propagation module\n",
    "\n",
    "### 4.1 - Linear Forward \n",
    "Now that you have initialized your parameters, you will do the forward propagation module. You will start by implementing some basic functions that you will use later when implementing the model. You will complete three functions in this order:\n",
    "\n",
    "- LINEAR\n",
    "- LINEAR -> ACTIVATION where ACTIVATION will be either ReLU or Sigmoid. \n",
    "- [LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID (whole model)\n",
    "\n",
    "The linear forward module (vectorized over all the examples) computes the following equations:\n",
    "\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\\tag{4}$$\n",
    "\n",
    "where $A^{[0]} = X$. \n",
    "\n",
    "**Exercise**: Build the linear part of forward propagation.\n",
    "\n",
    "**Reminder**:\n",
    "The mathematical representation of this unit is $Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$. You may also find `np.dot()` useful. If your dimensions don't match, printing `W.shape` may help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Linear-Activation Forward\n",
    "\n",
    "In this notebook, you will use two activation functions:\n",
    "\n",
    "- **Sigmoid**: $\\sigma(Z) = \\sigma(W A + b) = \\frac{1}{ 1 + e^{-(W A + b)}}$. We have provided you with the `sigmoid` function. This function returns **two** items: the activation value \"`a`\" and a \"`cache`\" that contains \"`Z`\" (it's what we will feed in to the corresponding backward function). To use it you could just call: \n",
    "``` python\n",
    "A, activation_cache = sigmoid(Z)\n",
    "```\n",
    "\n",
    "- **ReLU**: The mathematical formula for ReLu is $A = RELU(Z) = max(0, Z)$. We have provided you with the `relu` function. This function returns **two** items: the activation value \"`A`\" and a \"`cache`\" that contains \"`Z`\" (it's what we will feed in to the corresponding backward function). To use it you could just call:\n",
    "``` python\n",
    "A, activation_cache = relu(Z)\n",
    "```\n",
    "\n",
    "- **SoftMax**: $\\sigma (\\mathbf {z} )_{j}={\\frac {e^{z_{j}}}{\\sum _{k=1}^{K}e^{z_{k}}}}$. We have provided you with the `softmax` function. This function returns **two** items: the activation value \"`A`\" and a \"`cache`\" that contains \"`Z`\" (it's what we will feed in to the corresponding backward function). To use it you could just call:\n",
    "``` python\n",
    "A, activation_cache = softmax(Z)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
