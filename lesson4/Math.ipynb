{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The math of deep learning\n",
    "\n",
    "> What I cannot create, I do not understand - Richard Feynman \n",
    "\n",
    "![title](https://qph.ec.quoracdn.net/main-qimg-87833c78a604ff07a82ff7787574e197-c)\n",
    "\n",
    "Richard Feynman who is considered one of the greatest scientists who ever lived had something scribbled on his blackboard at the time of his death.\n",
    "\n",
    "What I cannot create I do not understand.\n",
    "\n",
    "So this time we will create in order to understand.\n",
    "\n",
    "\n",
    "## Input function\n",
    "![title](https://github.com/bcarlyle/Momentum-AI-machine-learning-course/raw/master/lesson4/files/xinput.png)\n",
    "## Optimization function\n",
    "![title](https://github.com/bcarlyle/Momentum-AI-machine-learning-course/raw/master/lesson4/files/optimization.gif)\n",
    "## Turing machine\n",
    "![title](https://github.com/bcarlyle/Momentum-AI-machine-learning-course/raw/master/lesson4/files/turing_machine.JPG)\n",
    "\n",
    "# Math in deep learning\n",
    "Deep learning draws math from three different sources, linear algebra, calculus and statistics. \n",
    "## Linear algebra\n",
    "http://machinelearningmastery.com/linear-algebra-machine-learning/\n",
    "## Calculus\n",
    "https://www.umiacs.umd.edu/~hal/courses/2013S_ML/math4ml.pdf\n",
    "## Statistics\n",
    "http://machinelearningmastery.com/crash-course-statistics-machine-learning/\n",
    "Neural network from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(-9,9)\n",
    "b = -5\n",
    "\n",
    "w = np.array([3])\n",
    "\n",
    "y = x*w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-32, -29, -26, -23, -20, -17, -14, -11,  -8,  -5,  -2,   1,   4,\n",
       "         7,  10,  13,  16,  19])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a line chart for y = k*x + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKRIqPBFRIqECl9EpEio8EVEisT/Af2Z5qnepNzlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f37c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.grid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### where is the minimum of this function??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(-7,9)\n",
    "b = -5\n",
    "\n",
    "w = np.array([3])\n",
    "\n",
    "y = x**2*w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parabol of the function y for minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ0UvhBApTopeCCFS3P8DVpxnr552huAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f455390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.grid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where is the minimum of this function???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher order of dimension, adding another input to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06100746/grad.png](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/03/06100746/grad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "![title](http://wiki.fast.ai/images/math/6/e/0/6e0e60f3b06c79ac0fddeca87dbc21dd.png)\n",
    "## Calculating derivative\n",
    "Let's write code to calculate the derivative for f(x) = x^2. We know the derivative should be 2x.\n",
    "\n",
    "## Derivatives in Deep Learning\n",
    "![title](https://media1.giphy.com/media/Fg9yN8G9RHvBS/giphy.gif)\n",
    "Machine learning uses derivatives to find optimal solutions to problems. It’s useful in optimization functions like Gradient Descent because it helps us decide whether to increase or decrease our weights in order to maximize or minimize some metrics (e.g. loss)\n",
    "\n",
    "It also helps us model nonlinear functions as linear functions (tangent lines), which have constant slopes. With a constant slope we can decide whether to move up or down the slope (increase or decrease our weights) to get closer to the target value (class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xSquared(x):\n",
    "    return x**2\n",
    "\n",
    "def getDeriv(func, x):\n",
    "  h = 0.0001\n",
    "  return (func(x+h) - func(x)) / h\n",
    "\n",
    "x = 3\n",
    "derivative = getDeriv(xSquared, x)\n",
    "actual = 2*x\n",
    "\n",
    "derivative, actual = 6.0001, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "## Making XOR\n",
    "![title](files/xor.png)\n",
    "Exclusive or or exclusive disjunction is a logical operation that outputs true only when inputs differ (one is true, the other is false).\n",
    "It is symbolized by the prefix operator J and by the infix operators XOR (/ˌɛks ˈɔːr/), EOR, EXOR, ⊻, ⊕, ↮, and ≢. The negation of XOR is logical biconditional, which outputs true only when both inputs are the same.\n",
    "It gains the name \"exclusive or\" because the meaning of \"or\" is ambiguous when both operands are true; the exclusive or operator excludes that case. This is sometimes thought of as \"one or the other but not both\". This could be written as \"A or B, but not, A and B\".\n",
    "More generally, XOR is true only when an odd number of inputs are true. A chain of XORs—a XOR b XOR c XOR d (and so on)—is true whenever an odd number of the inputs are true and is false whenever an even number of inputs are true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sigmoid function\n",
    "def nonlin(x, deriv=False):  \n",
    "    if(deriv==True):\n",
    "        return (x*(1-x))\n",
    "    \n",
    "    return 1/(1+np.exp(-x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the input matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#input data\n",
    "X = np.array([[0,0,1],  # Note: there is a typo on this line in the video\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the exclusive OR function follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#output data\n",
    "y = np.array([[0],\n",
    "             [1],\n",
    "             [1],\n",
    "             [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seed for the random generator is set so that it will return the same random numbers each time, which is sometimes useful for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we intialize the weights to random values. syn0 are the weights between the input layer and the hidden layer. It is a 3x4 matrix because there are two input weights plus a bias term (=3) and four nodes in the hidden layer (=4). syn1 are the weights between the hidden layer and the output layer. It is a 4x1 matrix because there are 4 nodes in the hidden layer and one output. Note that there is no bias term feeding the output layer in this example. The weights are initially generated randomly because optimization tends not to work well when all the weights start at the same value. Note that neither of the neural networks shown in the video describe the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synapses\n",
    "syn0 = 2*np.random.random((3,4)) - 1  # 3x4 matrix of weights ((2 inputs + 1 bias) x 4 nodes in the hidden layer)\n",
    "syn1 = 2*np.random.random((4,1)) - 1  # 4x1 matrix of weights. (4 nodes x 1 output) - no bias term in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main training loop. The output shows the evolution of the error between the model and desired. The error steadily decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.500386946116\n",
      "Error: 0.00867360161359\n",
      "Error: 0.00586357615026\n",
      "Error: 0.00469264457551\n",
      "Error: 0.0040148843226\n",
      "Error: 0.00356083564683\n",
      "Output after training\n",
      "[[ 0.00271394]\n",
      " [ 0.99695061]\n",
      " [ 0.99678411]\n",
      " [ 0.00394104]]\n"
     ]
    }
   ],
   "source": [
    "#training step\n",
    "# Python2 Note: In the follow command, you may improve \n",
    "#   performance by replacing 'range' with 'xrange'. \n",
    "for j in range(60000):  \n",
    "    \n",
    "    # Calculate forward through the network.\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0, syn0))\n",
    "    l2 = nonlin(np.dot(l1, syn1))\n",
    "    \n",
    "    # Back propagation of errors using the chain rule. \n",
    "    l2_error = y - l2\n",
    "    if(j % 10000) == 0:   # Only print the error every 10000 steps, to save time and limit the amount of output. \n",
    "        print(\"Error: \" + str(np.mean(np.abs(l2_error))))\n",
    "        \n",
    "    l2_delta = l2_error*nonlin(l2, deriv=True)\n",
    "    \n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "    \n",
    "    #update weights (no learning rate term)\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "    \n",
    "print(\"Output after training\")\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another implementation of XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02884591]\n",
      " [ 0.99902743]\n",
      " [ 0.99920954]\n",
      " [ 0.01610007]]\n"
     ]
    }
   ],
   "source": [
    "#   XOR.py-A very simple neural network to do exclusive or.\n",
    "#   sigmoid activation for hidden layer, no (or linear) activation for output\n",
    " \n",
    "import numpy as np\n",
    " \n",
    "epochs = 20000                                  # Number of iterations\n",
    "inputLayerSize, hiddenLayerSize, outputLayerSize = 2, 3, 1\n",
    "L = .1                                          # learning rate      \n",
    " \n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([ [0],   [1],   [1],   [0]])\n",
    " \n",
    "def sigmoid (x): return 1/(1 + np.exp(-x))      # activation function\n",
    "def sigmoid_(x): return x * (1 - x)             # derivative of sigmoid\n",
    "                                                # weights on layer inputs\n",
    "Wh = np.random.uniform(size=(inputLayerSize, hiddenLayerSize))\n",
    "Wz = np.random.uniform(size=(hiddenLayerSize,outputLayerSize))\n",
    " \n",
    "for i in range(epochs):\n",
    " \n",
    "    H = sigmoid(np.dot(X, Wh))                  # hidden layer results\n",
    "    Z = np.dot(H,Wz)                            # output layer, no activation\n",
    "    E = Y - Z                                   # how much we missed (error)\n",
    "    dZ = E * L                                  # delta Z\n",
    "    Wz +=  H.T.dot(dZ)                          # update output layer weights\n",
    "    dH = dZ.dot(Wz.T) * sigmoid_(H)             # delta H\n",
    "    Wh +=  X.T.dot(dH)                          # update hidden layer weights\n",
    "     \n",
    "print(Z)                # what have we learnt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "![title](https://codeahoy.com/img/blogs/deep_neural_network.png)\n",
    "## Neural network as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [1,2]])\n",
    "y = np.array([1,2])\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost1 = NN.costFunction(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,2) and (1,3) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-f6a9c7018642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdJdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdJdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcostFunctionPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-753de0d38bf5>\u001b[0m in \u001b[0;36mcostFunctionPrime\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdJdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mdelta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdJdW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,2) and (1,3) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "dJdW1, dJdW2 = NN.costFunctionPrime(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dJdW1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-628ecc409d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdJdW1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dJdW1' is not defined"
     ]
    }
   ],
   "source": [
    "dJdW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "![title](files/optimization.gif)\n",
    "## Graded function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Gradient Descent\n",
    "\n",
    "A simple optimization method in machine learning is gradient descent (GD). When you take gradient steps with respect to all $m$ examples on each step, it is also called Batch Gradient Descent. \n",
    "\n",
    "**Warm-up exercise**: Implement the gradient descent update rule. The  gradient descent rule is, for $l = 1, ..., L$: \n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} \\tag{1}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{2}$$\n",
    "\n",
    "where L is the number of layers and $\\alpha$ is the learning rate. All parameters should be stored in the `parameters` dictionary. Note that the iterator `l` starts at 0 in the `for` loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift `l` to `l+1` when coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'testCases_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-cd2cb3cc70a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtestCases_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdnn_utils_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'testCases_v2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v2 import *\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters_with_gd\n",
    "\n",
    "def update_parameters_with_gd(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using one step of gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters to be updated:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- python dictionary containing your gradients to update each parameters:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "\n",
    "    # Update rule for each parameter\n",
    "    for l in range(L):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        parameters[\"W\" + str(l+1)] = None\n",
    "        parameters[\"b\" + str(l+1)] = None\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "![title](https://www.kernix.com/doc/data/cnn.png)\n",
    "## Convolutinal network from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle #saving and loading our serialized model \n",
    "import numpy as np #matrix math\n",
    "from app.model.preprocessor import Preprocessor as img_prep #image preprocessing\n",
    "\n",
    "#class for loading our saved model and classifying new images\n",
    "class LiteOCR:\n",
    "    \n",
    "\tdef __init__(self, fn=\"alpha_weights.pkl\", pool_size=2):\n",
    "        #load the weights from the pickle file and the meta data\n",
    "\t\t[weights, meta] = pickle.load(open(fn, 'rb'), encoding='latin1') #currently, this class MUST be initialized from a pickle file\n",
    "\t\t#list to store labels\n",
    "        self.vocab = meta[\"vocab\"]\n",
    "        \n",
    "        #how many rows and columns in an image\n",
    "\t\tself.img_rows = meta[\"img_side\"] ; self.img_cols = meta[\"img_side\"]\n",
    "        \n",
    "        #load our CNN\n",
    "\t\tself.CNN = LiteCNN()\n",
    "        #with our saved weights\n",
    "\t\tself.CNN.load_weights(weights)\n",
    "        #define the pooling layers size\n",
    "\t\tself.CNN.pool_size=int(pool_size)\n",
    "    \n",
    "    #classify new image\n",
    "\tdef predict(self, image):\n",
    "\t\tprint(image.shape)\n",
    "        #vectorize the image into the right shape for our network\n",
    "\t\tX = np.reshape(image, (1, 1, self.img_rows, self.img_cols))\n",
    "\t\tX = X.astype(\"float32\")\n",
    "        \n",
    "        #make the prediction\n",
    "\t\tpredicted_i = self.CNN.predict(X)\n",
    "        #return the predicted label\n",
    "\t\treturn self.vocab[predicted_i]\n",
    "\n",
    "class LiteCNN:\n",
    "\tdef __init__(self):\n",
    "        # a place to store the layers\n",
    "\t\tself.layers = [] \n",
    "        # size of pooling area for max pooling\n",
    "\t\tself.pool_size = None \n",
    "\n",
    "\tdef load_weights(self, weights):\n",
    "\t\tassert not self.layers, \"Weights can only be loaded once!\"\n",
    "        #add the saved matrix values to the convolutional network\n",
    "\t\tfor k in range(len(weights.keys())):\n",
    "\t\t\tself.layers.append(weights['layer_{}'.format(k)])\n",
    "\n",
    "\tdef predict(self, X):        \n",
    "        #here is where the network magic happens at a high level\n",
    "        h = self.cnn_layer(X, layer_i=0, border_mode=\"full\"); X= h\n",
    "        h = self.relu_layer(X); X = h;\n",
    "        h = self.cnn_layer(X, layer_i=2, border_mode=\"valid\"); X = h\n",
    "        h = self.relu_layer(X); X = h;\n",
    "        h = self.maxpooling_layer(X); X = h\n",
    "        h = self.dropout_layer(X, .25); X = h\n",
    "        h = self.flatten_layer(X, layer_i=7); X = h;\n",
    "        h = self.dense_layer(X, fully, layer_i=10); x = H\n",
    "        h = self.softmax_layer2D(X); x = h\n",
    "        max_i = self.classify(X)\n",
    "        return max_i[0]\n",
    "    \n",
    "    #given our feature map we've learned from convolving around the image\n",
    "    #lets make it more dense by performing pooling, specifically max pooling\n",
    "    #we'll select the max values from the image matrix and use that as our new feature map\n",
    "\tdef maxpooling_layer(self, convolved_features):\n",
    "        #given our learned features and images\n",
    "\t\tnb_features = convolved_features.shape[0]\n",
    "\t\tnb_images = convolved_features.shape[1]\n",
    "\t\tconv_dim = convolved_features.shape[2]\n",
    "\t\tres_dim = int(conv_dim / self.pool_size)       #assumed square shape\n",
    "\n",
    "        #initialize our more dense feature list as empty\n",
    "\t\tpooled_features = np.zeros((nb_features, nb_images, res_dim, res_dim))\n",
    "        #for each image\n",
    "\t\tfor image_i in range(nb_images):\n",
    "            #and each feature map\n",
    "\t\t\tfor feature_i in range(nb_features):\n",
    "                #begin by the row\n",
    "\t\t\t\tfor pool_row in range(res_dim):\n",
    "                    #define start and end points\n",
    "\t\t\t\t\trow_start = pool_row * self.pool_size\n",
    "\t\t\t\t\trow_end   = row_start + self.pool_size\n",
    "\n",
    "                    #for each column (so its a 2D iteration)\n",
    "\t\t\t\t\tfor pool_col in range(res_dim):\n",
    "                        #define start and end points\n",
    "\t\t\t\t\t\tcol_start = pool_col * self.pool_size\n",
    "\t\t\t\t\t\tcol_end   = col_start + self.pool_size\n",
    "                        \n",
    "                        #define a patch given our defined starting ending points\n",
    "\t\t\t\t\t\tpatch = convolved_features[feature_i, image_i, row_start : row_end,col_start : col_end]\n",
    "                        #then take the max value from that patch\n",
    "                        #store it. this is our new learned feature/filter\n",
    "\t\t\t\t\t\tpooled_features[feature_i, image_i, pool_row, pool_col] = np.max(patch)\n",
    "\t\treturn pooled_features\n",
    "\n",
    "    #convolution is the most important of the matrix operations here\n",
    "    #well define our input, lauyer number, and a border mode (explained below)\n",
    "\tdef cnn_layer(self, X, layer_i=0, border_mode = \"full\"):\n",
    "        #we'll store our feature maps and bias value in these 2 vars\n",
    "\t\tfeatures = self.layers[layer_i][\"param_0\"]\n",
    "\t\tbias = self.layers[layer_i][\"param_1\"]\n",
    "        #how big is our filter/patch?\n",
    "\t\tpatch_dim = features[0].shape[-1]\n",
    "        #how many features do we have?\n",
    "\t\tnb_features = features.shape[0]\n",
    "        #How big is our image?\n",
    "\t\timage_dim = X.shape[2] #assume image square\n",
    "        #R G B values\n",
    "\t\timage_channels = X.shape[1]\n",
    "        #how many images do we have?\n",
    "\t\tnb_images = X.shape[0]\n",
    "        \n",
    "        #With border mode \"full\" you get an output that is the \"full\" size as the input. \n",
    "        #That means that the filter has to go outside the bounds of the input by \"filter size / 2\" - \n",
    "        #the area outside of the input is normally padded with zeros.\n",
    "\t\tif border_mode == \"full\":\n",
    "\t\t\tconv_dim = image_dim + patch_dim - 1\n",
    "        #With border mode \"valid\" you get an output that is smaller than the input because \n",
    "        #the convolution is only computed where the input and the filter fully overlap.\n",
    "\t\telif border_mode == \"valid\":\n",
    "\t\t\tconv_dim = image_dim - patch_dim + 1\n",
    "        \n",
    "        #we'll initialize our feature matrix\n",
    "\t\tconvolved_features = np.zeros((nb_images, nb_features, conv_dim, conv_dim));\n",
    "        #then we'll iterate through each image that we have\n",
    "\t\tfor image_i in range(nb_images):\n",
    "            #for each feature \n",
    "\t\t\tfor feature_i in range(nb_features):\n",
    "                #lets initialize a convolved image as empty\n",
    "\t\t\t\tconvolved_image = np.zeros((conv_dim, conv_dim))\n",
    "                #then for each channel (r g b )\n",
    "\t\t\t\tfor channel in range(image_channels):\n",
    "                    #lets extract a feature from our feature map\n",
    "\t\t\t\t\tfeature = features[feature_i, channel, :, :]\n",
    "                    #then define a channel specific part of our image\n",
    "\t\t\t\t\timage   = X[image_i, channel, :, :]\n",
    "                    #perform convolution on our image, using a given feature filter\n",
    "\t\t\t\t\tconvolved_image += self.convolve2d(image, feature, border_mode);\n",
    "\n",
    "                #add a bias to our convoved image\n",
    "\t\t\t\tconvolved_image = convolved_image + bias[feature_i]\n",
    "                #add it to our list of convolved features (learnings)\n",
    "\t\t\t\tconvolved_features[image_i, feature_i, :, :] = convolved_image\n",
    "\t\treturn convolved_features\n",
    "\n",
    "    #In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
    "\tdef dense_layer(self, X, layer_i=0):\n",
    "        #so we'll initialize our weight and bias for this layer\n",
    "\t\tW = self.layers[layer_i][\"param_0\"]\n",
    "\t\tb = self.layers[layer_i][\"param_1\"]\n",
    "        #and multiply it by our input (dot product)\n",
    "\t\toutput = np.dot(X, W) + b\n",
    "\t\treturn output\n",
    "\n",
    "\t@staticmethod\n",
    "    \n",
    "    #so what does the convolution operation look like?, given an image and a feature map (filter)\n",
    "\tdef convolve2d(image, feature, border_mode=\"full\"):\n",
    "        #we'll define the tensor dimensions of the image and the feature\n",
    "\t\timage_dim = np.array(image.shape)\n",
    "\t\tfeature_dim = np.array(feature.shape)\n",
    "        #as well as a target dimension\n",
    "\t\ttarget_dim = image_dim + feature_dim - 1\n",
    "        #then we'll perform a fast fourier transform on both the input and the filter\n",
    "        #performing a convolution can be written as a for loop but for many convolutions\n",
    "        #this approach is too comp. expensive/slow. it can be performed orders of magnitude\n",
    "        #faster using a fast fourier transform. \n",
    "\t\tfft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim)\n",
    "        #and set the result to our target \n",
    "\t\ttarget = np.fft.ifft2(fft_result).real\n",
    "\n",
    "\t\tif border_mode == \"valid\":\n",
    "\t\t\t# To compute a valid shape, either np.all(x_shape >= y_shape) or\n",
    "\t\t\t# np.all(y_shape >= x_shape).\n",
    "            #decide a target dimension to convolve around\n",
    "\t\t\tvalid_dim = image_dim - feature_dim + 1\n",
    "\t\t\tif np.any(valid_dim < 1):\n",
    "\t\t\t\tvalid_dim = feature_dim - image_dim + 1\n",
    "\t\t\tstart_i = (target_dim - valid_dim) // 2\n",
    "\t\t\tend_i = start_i + valid_dim\n",
    "\t\t\ttarget = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n",
    "\t\treturn target\n",
    "\n",
    "\tdef relu_layer(x):\n",
    "        #turn all negative values in a matrix into zeros\n",
    "\t\tz = np.zeros_like(x)\n",
    "\t\treturn np.where(x>z,x,z)\n",
    "\n",
    "\tdef softmax_layer2D(w):\n",
    "        #this function will calculate the probabilities of each\n",
    "        #target class over all possible target classes. \n",
    "\t\tmaxes = np.amax(w, axis=1)\n",
    "\t\tmaxes = maxes.reshape(maxes.shape[0], 1)\n",
    "\t\te = np.exp(w - maxes)\n",
    "\t\tdist = e / np.sum(e, axis=1, keepdims=True)\n",
    "\t\treturn dist\n",
    "\n",
    "    #affect the probability a node will be turned off by multiplying it\n",
    "    #by a p values (.25 we define)\n",
    "\tdef dropout_layer(X, p):\n",
    "\t\tretain_prob = 1. - p\n",
    "\t\tX *= retain_prob\n",
    "\t\treturn X\n",
    "\n",
    "    #get the largest probabililty value from the list\n",
    "\tdef classify(X):\n",
    "\t\treturn X.argmax(axis=-1)\n",
    "\n",
    "    #tensor transformation, less dimensions\n",
    "\tdef flatten_layer(X):\n",
    "\t\tflatX = np.zeros((X.shape[0],np.prod(X.shape[1:])))\n",
    "\t\tfor i in range(X.shape[0]):\n",
    "\t\t\tflatX[i,:] = X[i].flatten(order='C')\n",
    "\t\treturn flatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exericise 7\n",
    "![title](files/turing_machine.JPG)\n",
    "## LSTM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(values): \n",
    "    return values*(1-values)\n",
    "\n",
    "def tanh_derivative(values): \n",
    "    return 1. - values ** 2\n",
    "\n",
    "# createst uniform random array w/ values in [a,b) and shape args\n",
    "def rand_arr(a, b, *args): \n",
    "    np.random.seed(0)\n",
    "    return np.random.rand(*args) * (b - a) + a\n",
    "\n",
    "class LstmParam:\n",
    "    def __init__(self, mem_cell_ct, x_dim):\n",
    "        self.mem_cell_ct = mem_cell_ct\n",
    "        self.x_dim = x_dim\n",
    "        concat_len = x_dim + mem_cell_ct\n",
    "        # weight matrices\n",
    "        self.wg = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wi = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len) \n",
    "        self.wf = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        self.wo = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
    "        # bias terms\n",
    "        self.bg = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bi = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bf = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        self.bo = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
    "        # diffs (derivative of loss function w.r.t. all parameters)\n",
    "        self.wg_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wi_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wf_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.wo_diff = np.zeros((mem_cell_ct, concat_len)) \n",
    "        self.bg_diff = np.zeros(mem_cell_ct) \n",
    "        self.bi_diff = np.zeros(mem_cell_ct) \n",
    "        self.bf_diff = np.zeros(mem_cell_ct) \n",
    "        self.bo_diff = np.zeros(mem_cell_ct) \n",
    "\n",
    "    def apply_diff(self, lr = 1):\n",
    "        self.wg -= lr * self.wg_diff\n",
    "        self.wi -= lr * self.wi_diff\n",
    "        self.wf -= lr * self.wf_diff\n",
    "        self.wo -= lr * self.wo_diff\n",
    "        self.bg -= lr * self.bg_diff\n",
    "        self.bi -= lr * self.bi_diff\n",
    "        self.bf -= lr * self.bf_diff\n",
    "        self.bo -= lr * self.bo_diff\n",
    "        # reset diffs to zero\n",
    "        self.wg_diff = np.zeros_like(self.wg)\n",
    "        self.wi_diff = np.zeros_like(self.wi) \n",
    "        self.wf_diff = np.zeros_like(self.wf) \n",
    "        self.wo_diff = np.zeros_like(self.wo) \n",
    "        self.bg_diff = np.zeros_like(self.bg)\n",
    "        self.bi_diff = np.zeros_like(self.bi) \n",
    "        self.bf_diff = np.zeros_like(self.bf) \n",
    "        self.bo_diff = np.zeros_like(self.bo) \n",
    "\n",
    "class LstmState:\n",
    "    def __init__(self, mem_cell_ct, x_dim):\n",
    "        self.g = np.zeros(mem_cell_ct)\n",
    "        self.i = np.zeros(mem_cell_ct)\n",
    "        self.f = np.zeros(mem_cell_ct)\n",
    "        self.o = np.zeros(mem_cell_ct)\n",
    "        self.s = np.zeros(mem_cell_ct)\n",
    "        self.h = np.zeros(mem_cell_ct)\n",
    "        self.bottom_diff_h = np.zeros_like(self.h)\n",
    "        self.bottom_diff_s = np.zeros_like(self.s)\n",
    "    \n",
    "class LstmNode:\n",
    "    def __init__(self, lstm_param, lstm_state):\n",
    "        # store reference to parameters and to activations\n",
    "        self.state = lstm_state\n",
    "        self.param = lstm_param\n",
    "        # non-recurrent input concatenated with recurrent input\n",
    "        self.xc = None\n",
    "\n",
    "    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n",
    "        # if this is the first lstm node in the network\n",
    "        if s_prev is None: s_prev = np.zeros_like(self.state.s)\n",
    "        if h_prev is None: h_prev = np.zeros_like(self.state.h)\n",
    "        # save data for use in backprop\n",
    "        self.s_prev = s_prev\n",
    "        self.h_prev = h_prev\n",
    "\n",
    "        # concatenate x(t) and h(t-1)\n",
    "        xc = np.hstack((x,  h_prev))\n",
    "        self.state.g = np.tanh(np.dot(self.param.wg, xc) + self.param.bg)\n",
    "        self.state.i = sigmoid(np.dot(self.param.wi, xc) + self.param.bi)\n",
    "        self.state.f = sigmoid(np.dot(self.param.wf, xc) + self.param.bf)\n",
    "        self.state.o = sigmoid(np.dot(self.param.wo, xc) + self.param.bo)\n",
    "        self.state.s = self.state.g * self.state.i + s_prev * self.state.f\n",
    "        self.state.h = self.state.s * self.state.o\n",
    "\n",
    "        self.xc = xc\n",
    "    \n",
    "    def top_diff_is(self, top_diff_h, top_diff_s):\n",
    "        # notice that top_diff_s is carried along the constant error carousel\n",
    "        ds = self.state.o * top_diff_h + top_diff_s\n",
    "        do = self.state.s * top_diff_h\n",
    "        di = self.state.g * ds\n",
    "        dg = self.state.i * ds\n",
    "        df = self.s_prev * ds\n",
    "\n",
    "        # diffs w.r.t. vector inside sigma / tanh function\n",
    "        di_input = sigmoid_derivative(self.state.i) * di \n",
    "        df_input = sigmoid_derivative(self.state.f) * df \n",
    "        do_input = sigmoid_derivative(self.state.o) * do \n",
    "        dg_input = tanh_derivative(self.state.g) * dg\n",
    "\n",
    "        # diffs w.r.t. inputs\n",
    "        self.param.wi_diff += np.outer(di_input, self.xc)\n",
    "        self.param.wf_diff += np.outer(df_input, self.xc)\n",
    "        self.param.wo_diff += np.outer(do_input, self.xc)\n",
    "        self.param.wg_diff += np.outer(dg_input, self.xc)\n",
    "        self.param.bi_diff += di_input\n",
    "        self.param.bf_diff += df_input       \n",
    "        self.param.bo_diff += do_input\n",
    "        self.param.bg_diff += dg_input       \n",
    "\n",
    "        # compute bottom diff\n",
    "        dxc = np.zeros_like(self.xc)\n",
    "        dxc += np.dot(self.param.wi.T, di_input)\n",
    "        dxc += np.dot(self.param.wf.T, df_input)\n",
    "        dxc += np.dot(self.param.wo.T, do_input)\n",
    "        dxc += np.dot(self.param.wg.T, dg_input)\n",
    "\n",
    "        # save bottom diffs\n",
    "        self.state.bottom_diff_s = ds * self.state.f\n",
    "        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n",
    "\n",
    "class LstmNetwork():\n",
    "    def __init__(self, lstm_param):\n",
    "        self.lstm_param = lstm_param\n",
    "        self.lstm_node_list = []\n",
    "        # input sequence\n",
    "        self.x_list = []\n",
    "\n",
    "    def y_list_is(self, y_list, loss_layer):\n",
    "        \"\"\"\n",
    "        Updates diffs by setting target sequence \n",
    "        with corresponding loss layer. \n",
    "        Will *NOT* update parameters.  To update parameters,\n",
    "        call self.lstm_param.apply_diff()\n",
    "        \"\"\"\n",
    "        assert len(y_list) == len(self.x_list)\n",
    "        idx = len(self.x_list) - 1\n",
    "        # first node only gets diffs from label ...\n",
    "        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "        diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n",
    "        diff_s = np.zeros(self.lstm_param.mem_cell_ct)\n",
    "        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "        idx -= 1\n",
    "\n",
    "        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n",
    "        ### we also propagate error along constant error carousel using diff_s\n",
    "        while idx >= 0:\n",
    "            loss += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n",
    "            diff_s = self.lstm_node_list[idx + 1].state.bottom_diff_s\n",
    "            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "            idx -= 1 \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def x_list_clear(self):\n",
    "        self.x_list = []\n",
    "\n",
    "    def x_list_add(self, x):\n",
    "        self.x_list.append(x)\n",
    "        if len(self.x_list) > len(self.lstm_node_list):\n",
    "            # need to add new lstm node, create new state mem\n",
    "            lstm_state = LstmState(self.lstm_param.mem_cell_ct, self.lstm_param.x_dim)\n",
    "            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n",
    "\n",
    "        # get index of most recent x input\n",
    "        idx = len(self.x_list) - 1\n",
    "        if idx == 0:\n",
    "            # no recurrent inputs yet\n",
    "            self.lstm_node_list[idx].bottom_data_is(x)\n",
    "        else:\n",
    "            s_prev = self.lstm_node_list[idx - 1].state.s\n",
    "            h_prev = self.lstm_node_list[idx - 1].state.h\n",
    "            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
